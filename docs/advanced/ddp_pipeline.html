


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Training Transformer models using Distributed Data Parallel and Pipeline Parallelism &mdash; PyTorch Tutorials 1.8.1+cu102 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="../_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
  <link rel="stylesheet" href="../_static/gallery.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Image Segmentation DeepLabV3 on iOS" href="../beginner/deeplabv3_on_ios.html" />
    <link rel="prev" title="Training Transformer models using Pipeline Parallelism" href="../intermediate/pipeline_tutorial.html" /> 

  
  <script src="../_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="../_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css" integrity="sha384-vSIIfh2YWi9wW0r9iZe7RJPrKwp6bG+s9QZMoITbCckVJqGCCRhc+ccxNcdpHuYu" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/vision/stable/index.html">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/elastic/">
                  <span class="dropdown-title">TorchElastic</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorchâ€™s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  1.8.1+cu102
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search Tutorials" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
            
            
              
            
            
              <p class="caption"><span class="caption-text">PyTorch Recipes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../recipes/recipes_index.html">See All Recipes</a></li>
<li class="toctree-l1"><a class="reference internal" href="../prototype/prototype_index.html">See All Prototype Recipes</a></li>
</ul>
<p class="caption"><span class="caption-text">Learning PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/basics/intro.html">Learn the Basics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deep_learning_60min_blitz.html">Deep Learning with PyTorch: A 60 Minute Blitz</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/pytorch_with_examples.html">Learning PyTorch with Examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/nn_tutorial.html">What is <cite>torch.nn</cite> <em>really</em>?</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/tensorboard_tutorial.html">Visualizing Models, Data, and Training with TensorBoard</a></li>
</ul>
<p class="caption"><span class="caption-text">Image and Video</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/torchvision_tutorial.html">TorchVision Object Detection Finetuning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/transfer_learning_tutorial.html">Transfer Learning for Computer Vision Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/fgsm_tutorial.html">Adversarial Example Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/dcgan_faces_tutorial.html">DCGAN Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/vt_tutorial.html">Optimizing Vision Transformer Model for Deployment</a></li>
</ul>
<p class="caption"><span class="caption-text">Audio</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_preprocessing_tutorial.html">Audio manipulation with torchaudio</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_preprocessing_tutorial.html#audio-i-o">Audio I/O</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_preprocessing_tutorial.html#data-augmentation">Data Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_preprocessing_tutorial.html#feature-extractions">Feature Extractions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_preprocessing_tutorial.html#feature-augmentation">Feature Augmentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/audio_preprocessing_tutorial.html#datasets">Datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/speech_command_recognition_with_torchaudio.html">Speech Command Recognition with torchaudio</a></li>
</ul>
<p class="caption"><span class="caption-text">Text</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/transformer_tutorial.html">Sequence-to-Sequence Modeling with nn.Transformer and TorchText</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_classification_tutorial.html">NLP From Scratch: Classifying Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/char_rnn_generation_tutorial.html">NLP From Scratch: Generating Names with a Character-Level RNN</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/seq2seq_translation_tutorial.html">NLP From Scratch: Translation with a Sequence to Sequence Network and Attention</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/text_sentiment_ngrams_tutorial.html">Text classification with the torchtext library</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/torchtext_translation.html">Language Translation with TorchText</a></li>
</ul>
<p class="caption"><span class="caption-text">Reinforcement Learning</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/reinforcement_q_learning.html">Reinforcement Learning (DQN) Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/mario_rl_tutorial.html">Train a Mario-playing RL Agent</a></li>
</ul>
<p class="caption"><span class="caption-text">Deploying PyTorch Models in Production</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/flask_rest_api_tutorial.html">Deploying PyTorch in Python via a REST API with Flask</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/Intro_to_TorchScript_tutorial.html">Introduction to TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_export.html">Loading a TorchScript Model in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="super_resolution_with_onnxruntime.html">(optional) Exporting a Model from PyTorch to ONNX and Running it using ONNX Runtime</a></li>
</ul>
<p class="caption"><span class="caption-text">Code Transforms with FX</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/fx_conv_bn_fuser.html">(beta) Building a Convolution/Batch Norm fuser in FX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/fx_profiling_tutorial.html">(beta) Building a Simple CPU Performance Profiler with FX</a></li>
</ul>
<p class="caption"><span class="caption-text">Frontend APIs</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/memory_format_tutorial.html">(beta) Channels Last Memory Format in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_frontend.html">Using the PyTorch C++ Frontend</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch-script-parallelism.html">Dynamic Parallelism in TorchScript</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_autograd.html">Autograd in C++ Frontend</a></li>
</ul>
<p class="caption"><span class="caption-text">Extending PyTorch</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cpp_extension.html">Custom C++ and CUDA Extensions</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_script_custom_ops.html">Extending TorchScript with Custom C++ Operators</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch_script_custom_classes.html">Extending TorchScript with Custom C++ Classes</a></li>
<li class="toctree-l1"><a class="reference internal" href="dispatcher.html">Registering a Dispatched Operator in C++</a></li>
<li class="toctree-l1"><a class="reference internal" href="extend_dispatcher.html">Extending dispatcher for a new backend in C++</a></li>
</ul>
<p class="caption"><span class="caption-text">Model Optimization</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/profiler.html">Profiling your PyTorch Module</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/hyperparameter_tuning_tutorial.html">Hyperparameter tuning with Ray Tune</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pruning_tutorial.html">Pruning Tutorial</a></li>
<li class="toctree-l1"><a class="reference internal" href="dynamic_quantization_tutorial.html">(beta) Dynamic Quantization on an LSTM Word Language Model</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dynamic_quantization_bert_tutorial.html">(beta) Dynamic Quantization on BERT</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/quantized_transfer_learning_tutorial.html">(beta) Quantized Transfer Learning for Computer Vision Tutorial</a></li>
</ul>
<p class="caption"><span class="caption-text">Parallel and Distributed Training</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../beginner/dist_overview.html">PyTorch Distributed Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/model_parallel_tutorial.html">Single-Machine Model Parallel Best Practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/ddp_tutorial.html">Getting Started with Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_tuto.html">Writing Distributed Applications with PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_tutorial.html">Getting Started with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_param_server_tutorial.html">Implementing a Parameter Server Using Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/dist_pipeline_parallel_tutorial.html">Distributed Pipeline Parallelism Using RPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/rpc_async_execution.html">Implementing Batch RPC Processing Using Asynchronous Executions</a></li>
<li class="toctree-l1"><a class="reference internal" href="rpc_ddp_tutorial.html">Combining Distributed DataParallel with Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="../intermediate/pipeline_tutorial.html">Training Transformer models using Pipeline Parallelism</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Training Transformer models using Distributed Data Parallel and Pipeline Parallelism</a></li>
</ul>
<p class="caption"><span class="caption-text">Mobile</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deeplabv3_on_ios.html">Image Segmentation DeepLabV3 on iOS</a></li>
<li class="toctree-l1"><a class="reference internal" href="../beginner/deeplabv3_on_android.html">Image Segmentation DeepLabV3 on Android</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="../index.html">
          
            Tutorials
          
        </a> &gt;
      </li>

        
      <li>Training Transformer models using Distributed Data Parallel and Pipeline Parallelism</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="../_sources/advanced/ddp_pipeline.rst.txt" rel="nofollow"><img src="../_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        

          <div class="pytorch-call-to-action-links">
            <div id="tutorial-type">advanced/ddp_pipeline</div>

            <div id="google-colab-link">
              <img class="call-to-action-img" src="../_static/images/pytorch-colab.svg"/>
              <div class="call-to-action-desktop-view">Run in Google Colab</div>
              <div class="call-to-action-mobile-view">Colab</div>
            </div>
            <div id="download-notebook-link">
              <img class="call-to-action-notebook-img" src="../_static/images/pytorch-download.svg"/>
              <div class="call-to-action-desktop-view">Download Notebook</div>
              <div class="call-to-action-mobile-view">Notebook</div>
            </div>
            <div id="github-view-link">
              <img class="call-to-action-img" src="../_static/images/pytorch-github.svg"/>
              <div class="call-to-action-desktop-view">View on GitHub</div>
              <div class="call-to-action-mobile-view">GitHub</div>
            </div>
          </div>

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="sphx-glr-download-link-note admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Click <a class="reference internal" href="#sphx-glr-download-advanced-ddp-pipeline-py"><span class="std std-ref">here</span></a> to download the full example code</p>
</div>
<div class="sphx-glr-example-title section" id="training-transformer-models-using-distributed-data-parallel-and-pipeline-parallelism">
<span id="sphx-glr-advanced-ddp-pipeline-py"></span><h1>Training Transformer models using Distributed Data Parallel and Pipeline Parallelism<a class="headerlink" href="#training-transformer-models-using-distributed-data-parallel-and-pipeline-parallelism" title="Permalink to this headline">Â¶</a></h1>
<p><strong>Author</strong>: <a class="reference external" href="https://github.com/pritamdamania87">Pritam Damania</a></p>
<p>This tutorial demonstrates how to train a large Transformer model across
multiple GPUs using <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html">Distributed Data Parallel</a> and
<a class="reference external" href="https://pytorch.org/docs/stable/pipeline.html">Pipeline Parallelism</a>. This tutorial is an extension of the
<a class="reference external" href="https://pytorch.org/tutorials/beginner/transformer_tutorial.html">Sequence-to-Sequence Modeling with nn.Transformer and TorchText</a> tutorial
and scales up the same model to demonstrate how Distributed Data Parallel and
Pipeline Parallelism can be used to train Transformer models.</p>
<p>Prerequisites:</p>
<blockquote>
<div><ul class="simple">
<li><a class="reference external" href="https://pytorch.org/docs/stable/pipeline.html">Pipeline Parallelism</a></li>
<li><a class="reference external" href="https://pytorch.org/tutorials/beginner/transformer_tutorial.html">Sequence-to-Sequence Modeling with nn.Transformer and TorchText</a></li>
<li><a class="reference external" href="https://pytorch.org/tutorials/intermediate/ddp_tutorial.html">Getting Started with Distributed Data Parallel</a></li>
</ul>
</div></blockquote>
<div class="section" id="define-the-model">
<h2>Define the model<a class="headerlink" href="#define-the-model" title="Permalink to this headline">Â¶</a></h2>
<p><code class="docutils literal notranslate"><span class="pre">PositionalEncoding</span></code> module injects some information about the
relative or absolute position of the tokens in the sequence. The
positional encodings have the same dimension as the embeddings so that
the two can be summed. Here, we use <code class="docutils literal notranslate"><span class="pre">sine</span></code> and <code class="docutils literal notranslate"><span class="pre">cosine</span></code> functions of
different frequencies.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">tempfile</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">TransformerEncoder</span><span class="p">,</span> <span class="n">TransformerEncoderLayer</span>

<span class="k">class</span> <span class="nc">PositionalEncoding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">5000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">PositionalEncoding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>

        <span class="n">pe</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">d_model</span><span class="p">)</span>
        <span class="n">position</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">div_term</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">d_model</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span> <span class="o">*</span> <span class="p">(</span><span class="o">-</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mf">10000.0</span><span class="p">)</span> <span class="o">/</span> <span class="n">d_model</span><span class="p">))</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="n">pe</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">position</span> <span class="o">*</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="n">pe</span> <span class="o">=</span> <span class="n">pe</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s1">&#39;pe&#39;</span><span class="p">,</span> <span class="n">pe</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">pe</span><span class="p">[:</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="p">:]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
<p>In this tutorial, we will split a Transformer model across two GPUs and use
pipeline parallelism to train the model. In addition to this, we use
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.parallel.DistributedDataParallel.html">Distributed Data Parallel</a>
to train two replicas of this pipeline. We have one process driving a pipe across
GPUs 0 and 1 and another process driving a pipe across GPUs 2 and 3. Both these
processes then use Distributed Data Parallel to train the two replicas. The
model is exactly the same model used in the <a class="reference external" href="https://pytorch.org/tutorials/beginner/transformer_tutorial.html">Sequence-to-Sequence Modeling with nn.Transformer and TorchText</a> tutorial,
but is split into two stages. The largest number of parameters belong to the
<a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html">nn.TransformerEncoder</a> layer.
The <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoder.html">nn.TransformerEncoder</a>
itself consists of <code class="docutils literal notranslate"><span class="pre">nlayers</span></code> of <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.TransformerEncoderLayer.html">nn.TransformerEncoderLayer</a>.
As a result, our focus is on <code class="docutils literal notranslate"><span class="pre">nn.TransformerEncoder</span></code> and we split the model
such that half of the <code class="docutils literal notranslate"><span class="pre">nn.TransformerEncoderLayer</span></code> are on one GPU and the
other half are on another. To do this, we pull out the <code class="docutils literal notranslate"><span class="pre">Encoder</span></code> and
<code class="docutils literal notranslate"><span class="pre">Decoder</span></code> sections into seperate modules and then build an nn.Sequential
representing the original Transformer module.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">sys</span><span class="o">.</span><span class="n">platform</span> <span class="o">==</span> <span class="s1">&#39;win32&#39;</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Windows platform is not supported for pipeline parallelism&#39;</span><span class="p">)</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">4</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Need at least four GPU devices for this tutorial&#39;</span><span class="p">)</span>
    <span class="n">sys</span><span class="o">.</span><span class="n">exit</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntoken</span><span class="p">,</span> <span class="n">ninp</span><span class="p">,</span> <span class="n">dropout</span><span class="o">=</span><span class="mf">0.5</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">src_mask</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoder</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">ninp</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">ntoken</span><span class="p">,</span> <span class="n">ninp</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ninp</span> <span class="o">=</span> <span class="n">ninp</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">initrange</span> <span class="o">=</span> <span class="mf">0.1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">initrange</span><span class="p">,</span> <span class="n">initrange</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_generate_square_subsequent_mask</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sz</span><span class="p">):</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">triu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">sz</span><span class="p">,</span> <span class="n">sz</span><span class="p">))</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">))</span><span class="o">.</span><span class="n">masked_fill</span><span class="p">(</span><span class="n">mask</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="mf">0.0</span><span class="p">))</span>
        <span class="k">return</span> <span class="n">mask</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">src</span><span class="p">):</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">src_mask</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="bp">self</span><span class="o">.</span><span class="n">src_mask</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">!=</span> <span class="n">src</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">):</span>
            <span class="n">device</span> <span class="o">=</span> <span class="n">src</span><span class="o">.</span><span class="n">device</span>
            <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_generate_square_subsequent_mask</span><span class="p">(</span><span class="n">src</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">src_mask</span> <span class="o">=</span> <span class="n">mask</span>

        <span class="n">src</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">src</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">ninp</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoder</span><span class="p">(</span><span class="n">src</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ntoken</span><span class="p">,</span> <span class="n">ninp</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">ninp</span><span class="p">,</span> <span class="n">ntoken</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">init_weights</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">init_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">initrange</span> <span class="o">=</span> <span class="mf">0.1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="o">-</span><span class="n">initrange</span><span class="p">,</span> <span class="n">initrange</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inp</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="start-multiple-processes-for-training">
<h2>Start multiple processes for training<a class="headerlink" href="#start-multiple-processes-for-training" title="Permalink to this headline">Â¶</a></h2>
<p>We start two processes where each process drives its own pipeline across two
GPUs. <code class="docutils literal notranslate"><span class="pre">run_worker</span></code> is executed for each process.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">run_worker</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">):</span>
</pre></div>
</div>
</div>
<div class="section" id="load-and-batch-data">
<h2>Load and batch data<a class="headerlink" href="#load-and-batch-data" title="Permalink to this headline">Â¶</a></h2>
<p>The training process uses Wikitext-2 dataset from <code class="docutils literal notranslate"><span class="pre">torchtext</span></code>. The
vocab object is built based on the train dataset and is used to numericalize
tokens into tensors. Starting from sequential data, the <code class="docutils literal notranslate"><span class="pre">batchify()</span></code>
function arranges the dataset into columns, trimming off any tokens remaining
after the data has been divided into batches of size <code class="docutils literal notranslate"><span class="pre">batch_size</span></code>.
For instance, with the alphabet as the sequence (total length of 26)
and a batch size of 4, we would divide the alphabet into 4 sequences of
length 6:</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{bmatrix}
\text{A} &amp; \text{B} &amp; \text{C} &amp; \ldots &amp; \text{X} &amp; \text{Y} &amp; \text{Z}
\end{bmatrix}
\Rightarrow
\begin{bmatrix}
\begin{bmatrix}\text{A} \\ \text{B} \\ \text{C} \\ \text{D} \\ \text{E} \\ \text{F}\end{bmatrix} &amp;
\begin{bmatrix}\text{G} \\ \text{H} \\ \text{I} \\ \text{J} \\ \text{K} \\ \text{L}\end{bmatrix} &amp;
\begin{bmatrix}\text{M} \\ \text{N} \\ \text{O} \\ \text{P} \\ \text{Q} \\ \text{R}\end{bmatrix} &amp;
\begin{bmatrix}\text{S} \\ \text{T} \\ \text{U} \\ \text{V} \\ \text{W} \\ \text{X}\end{bmatrix}
\end{bmatrix}\end{split}\]</div>
<p>These columns are treated as independent by the model, which means that
the dependence of <code class="docutils literal notranslate"><span class="pre">G</span></code> and <code class="docutils literal notranslate"><span class="pre">F</span></code> can not be learned, but allows more
efficient batch processing.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># In &#39;run_worker&#39;</span>
    <span class="k">def</span> <span class="nf">print_with_rank</span><span class="p">(</span><span class="n">msg</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[RANK </span><span class="si">{}</span><span class="s1">]: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rank</span><span class="p">,</span> <span class="n">msg</span><span class="p">))</span>

    <span class="kn">import</span> <span class="nn">io</span>
    <span class="kn">from</span> <span class="nn">torchtext.utils</span> <span class="kn">import</span> <span class="n">download_from_url</span><span class="p">,</span> <span class="n">extract_archive</span>
    <span class="kn">from</span> <span class="nn">torchtext.data.utils</span> <span class="kn">import</span> <span class="n">get_tokenizer</span>
    <span class="kn">from</span> <span class="nn">torchtext.vocab</span> <span class="kn">import</span> <span class="n">build_vocab_from_iterator</span>

    <span class="n">url</span> <span class="o">=</span> <span class="s1">&#39;https://s3.amazonaws.com/research.metamind.io/wikitext/wikitext-2-v1.zip&#39;</span>
    <span class="n">test_filepath</span><span class="p">,</span> <span class="n">valid_filepath</span><span class="p">,</span> <span class="n">train_filepath</span> <span class="o">=</span> <span class="n">extract_archive</span><span class="p">(</span><span class="n">download_from_url</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">root</span><span class="o">=</span><span class="s2">&quot;.data</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">rank</span><span class="p">)))</span>
    <span class="n">tokenizer</span> <span class="o">=</span> <span class="n">get_tokenizer</span><span class="p">(</span><span class="s1">&#39;basic_english&#39;</span><span class="p">)</span>
    <span class="n">vocab</span> <span class="o">=</span> <span class="n">build_vocab_from_iterator</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">,</span>
                                          <span class="nb">iter</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">train_filepath</span><span class="p">,</span>
                                                       <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf8&quot;</span><span class="p">))))</span>

    <span class="k">def</span> <span class="nf">data_process</span><span class="p">(</span><span class="n">raw_text_iter</span><span class="p">):</span>
      <span class="n">data</span> <span class="o">=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">vocab</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">item</span><span class="p">)],</span>
                           <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span> <span class="k">for</span> <span class="n">item</span> <span class="ow">in</span> <span class="n">raw_text_iter</span><span class="p">]</span>
      <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="nb">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">t</span><span class="p">:</span> <span class="n">t</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">data</span><span class="p">)))</span>

    <span class="n">train_data</span> <span class="o">=</span> <span class="n">data_process</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">train_filepath</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf8&quot;</span><span class="p">)))</span>
    <span class="n">val_data</span> <span class="o">=</span> <span class="n">data_process</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">valid_filepath</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf8&quot;</span><span class="p">)))</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="n">data_process</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">io</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">test_filepath</span><span class="p">,</span> <span class="n">encoding</span><span class="o">=</span><span class="s2">&quot;utf8&quot;</span><span class="p">)))</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">rank</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">batchify</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">bsz</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">,</span> <span class="n">is_train</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="c1"># Divide the dataset into bsz parts.</span>
        <span class="n">nbatch</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">//</span> <span class="n">bsz</span>
        <span class="c1"># Trim off any extra elements that wouldn&#39;t cleanly fit (remainders).</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">narrow</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">nbatch</span> <span class="o">*</span> <span class="n">bsz</span><span class="p">)</span>
        <span class="c1"># Evenly divide the data across the bsz batches.</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">bsz</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">t</span><span class="p">()</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span>
        <span class="c1"># Divide the data across the ranks only for training data.</span>
        <span class="k">if</span> <span class="n">is_train</span><span class="p">:</span>
            <span class="n">data_per_rank</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">//</span> <span class="n">world_size</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">[</span><span class="n">rank</span> <span class="o">*</span> <span class="n">data_per_rank</span> <span class="p">:</span> <span class="p">(</span><span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">data_per_rank</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">data</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">20</span>
    <span class="n">eval_batch_size</span> <span class="o">=</span> <span class="mi">10</span>
    <span class="n">train_data</span> <span class="o">=</span> <span class="n">batchify</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">val_data</span> <span class="o">=</span> <span class="n">batchify</span><span class="p">(</span><span class="n">val_data</span><span class="p">,</span> <span class="n">eval_batch_size</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">)</span>
    <span class="n">test_data</span> <span class="o">=</span> <span class="n">batchify</span><span class="p">(</span><span class="n">test_data</span><span class="p">,</span> <span class="n">eval_batch_size</span><span class="p">,</span> <span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="functions-to-generate-input-and-target-sequence">
<h3>Functions to generate input and target sequence<a class="headerlink" href="#functions-to-generate-input-and-target-sequence" title="Permalink to this headline">Â¶</a></h3>
<p><code class="docutils literal notranslate"><span class="pre">get_batch()</span></code> function generates the input and target sequence for
the transformer model. It subdivides the source data into chunks of
length <code class="docutils literal notranslate"><span class="pre">bptt</span></code>. For the language modeling task, the model needs the
following words as <code class="docutils literal notranslate"><span class="pre">Target</span></code>. For example, with a <code class="docutils literal notranslate"><span class="pre">bptt</span></code> value of 2,
weâ€™d get the following two Variables for <code class="docutils literal notranslate"><span class="pre">i</span></code> = 0:</p>
<img alt="../_images/transformer_input_target.png" src="../_images/transformer_input_target.png" />
<p>It should be noted that the chunks are along dimension 0, consistent
with the <code class="docutils literal notranslate"><span class="pre">S</span></code> dimension in the Transformer model. The batch dimension
<code class="docutils literal notranslate"><span class="pre">N</span></code> is along dimension 1.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># In &#39;run_worker&#39;</span>
    <span class="n">bptt</span> <span class="o">=</span> <span class="mi">35</span>
    <span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="n">i</span><span class="p">):</span>
        <span class="n">seq_len</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">bptt</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">source</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">i</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">source</span><span class="p">[</span><span class="n">i</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="n">seq_len</span><span class="p">]</span>
        <span class="n">target</span> <span class="o">=</span> <span class="n">source</span><span class="p">[</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">:</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="o">+</span><span class="n">seq_len</span><span class="p">]</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">data</span><span class="p">,</span> <span class="n">target</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="model-scale-and-pipe-initialization">
<h2>Model scale and Pipe initialization<a class="headerlink" href="#model-scale-and-pipe-initialization" title="Permalink to this headline">Â¶</a></h2>
<p>To demonstrate training large Transformer models using pipeline parallelism,
we scale up the Transformer layers appropriately. We use an embedding
dimension of 4096, hidden size of 4096, 16 attention heads and 8 total
transformer layers (<code class="docutils literal notranslate"><span class="pre">nn.TransformerEncoderLayer</span></code>). This creates a model with
<strong>~1 billion</strong> parameters.</p>
<p>We need to initialize the <a class="reference external" href="https://pytorch.org/docs/stable/rpc.html">RPC Framework</a>
since Pipe depends on the RPC framework via <a class="reference external" href="https://pytorch.org/docs/stable/rpc.html#rref">RRef</a>
which allows for future expansion to cross host pipelining. We need to
initialize the RPC framework with only a single worker since weâ€™re using a
single process to drive multiple GPUs.</p>
<p>The pipeline is then initialized with 8 transformer layers on one GPU and 8
transformer layers on the other GPU. One pipe is setup across GPUs 0 and 1 and
another across GPUs 2 and 3. Both pipes are then replicated using DistributedDataParallel.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># In &#39;run_worker&#39;</span>
    <span class="n">ntokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">stoi</span><span class="p">)</span> <span class="c1"># the size of vocabulary</span>
    <span class="n">emsize</span> <span class="o">=</span> <span class="mi">4096</span> <span class="c1"># embedding dimension</span>
    <span class="n">nhid</span> <span class="o">=</span> <span class="mi">4096</span> <span class="c1"># the dimension of the feedforward network model in nn.TransformerEncoder</span>
    <span class="n">nlayers</span> <span class="o">=</span> <span class="mi">8</span> <span class="c1"># the number of nn.TransformerEncoderLayer in nn.TransformerEncoder</span>
    <span class="n">nhead</span> <span class="o">=</span> <span class="mi">16</span> <span class="c1"># the number of heads in the multiheadattention models</span>
    <span class="n">dropout</span> <span class="o">=</span> <span class="mf">0.2</span> <span class="c1"># the dropout value</span>

    <span class="kn">from</span> <span class="nn">torch.distributed</span> <span class="kn">import</span> <span class="n">rpc</span>
    <span class="n">tmpfile</span> <span class="o">=</span> <span class="n">tempfile</span><span class="o">.</span><span class="n">NamedTemporaryFile</span><span class="p">()</span>
    <span class="n">rpc</span><span class="o">.</span><span class="n">init_rpc</span><span class="p">(</span>
        <span class="n">name</span><span class="o">=</span><span class="s2">&quot;worker&quot;</span><span class="p">,</span>
        <span class="n">rank</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="n">world_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
        <span class="n">rpc_backend_options</span><span class="o">=</span><span class="n">rpc</span><span class="o">.</span><span class="n">TensorPipeRpcBackendOptions</span><span class="p">(</span>
            <span class="n">init_method</span><span class="o">=</span><span class="s2">&quot;file://</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tmpfile</span><span class="o">.</span><span class="n">name</span><span class="p">),</span>
            <span class="c1"># Specifying _transports and _channels is a workaround and we no longer</span>
            <span class="c1"># will have to specify _transports and _channels for PyTorch</span>
            <span class="c1"># versions &gt;= 1.8.1</span>
            <span class="n">_transports</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;ibv&quot;</span><span class="p">,</span> <span class="s2">&quot;uv&quot;</span><span class="p">],</span>
            <span class="n">_channels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;cuda_ipc&quot;</span><span class="p">,</span> <span class="s2">&quot;cuda_basic&quot;</span><span class="p">],</span>
        <span class="p">)</span>
    <span class="p">)</span>

    <span class="c1"># Num gpus for model parallelism.</span>
    <span class="n">num_gpus</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">partition_len</span> <span class="o">=</span> <span class="p">((</span><span class="n">nlayers</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">num_gpus</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>

    <span class="c1"># Add encoder in the beginning.</span>
    <span class="n">tmp_list</span> <span class="o">=</span> <span class="p">[</span><span class="n">Encoder</span><span class="p">(</span><span class="n">ntokens</span><span class="p">,</span> <span class="n">emsize</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">rank</span><span class="p">)]</span>
    <span class="n">module_list</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="c1"># Add all the necessary transformer blocks.</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">nlayers</span><span class="p">):</span>
        <span class="n">transformer_block</span> <span class="o">=</span> <span class="n">TransformerEncoderLayer</span><span class="p">(</span><span class="n">emsize</span><span class="p">,</span> <span class="n">nhead</span><span class="p">,</span> <span class="n">nhid</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">%</span> <span class="p">(</span><span class="n">partition_len</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">module_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">tmp_list</span><span class="p">))</span>
            <span class="n">tmp_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">device</span> <span class="o">=</span> <span class="n">i</span> <span class="o">//</span> <span class="p">(</span><span class="n">partition_len</span><span class="p">)</span>
        <span class="n">tmp_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">transformer_block</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">rank</span> <span class="o">+</span> <span class="n">device</span><span class="p">))</span>

    <span class="c1"># Add decoder in the end.</span>
    <span class="n">tmp_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">Decoder</span><span class="p">(</span><span class="n">ntokens</span><span class="p">,</span> <span class="n">emsize</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">rank</span> <span class="o">+</span> <span class="n">num_gpus</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">module_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">tmp_list</span><span class="p">))</span>

    <span class="c1"># Need to use &#39;checkpoint=never&#39; since as of PyTorch 1.8, Pipe checkpointing</span>
    <span class="c1"># doesn&#39;t work with DDP.</span>
    <span class="kn">from</span> <span class="nn">torch.distributed.pipeline.sync</span> <span class="kn">import</span> <span class="n">Pipe</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">Pipe</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
        <span class="o">*</span><span class="n">module_list</span><span class="p">),</span> <span class="n">chunks</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span> <span class="n">checkpoint</span><span class="o">=</span><span class="s2">&quot;never&quot;</span><span class="p">)</span>

    <span class="c1"># Initialize process group and wrap model in DDP.</span>
    <span class="kn">from</span> <span class="nn">torch.nn.parallel</span> <span class="kn">import</span> <span class="n">DistributedDataParallel</span>
    <span class="kn">import</span> <span class="nn">torch.distributed</span> <span class="k">as</span> <span class="nn">dist</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_ADDR&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;localhost&#39;</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;MASTER_PORT&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;29500&#39;</span>
    <span class="n">dist</span><span class="o">.</span><span class="n">init_process_group</span><span class="p">(</span>
                <span class="n">backend</span><span class="o">=</span><span class="s2">&quot;nccl&quot;</span><span class="p">,</span> <span class="n">rank</span><span class="o">=</span><span class="n">rank</span><span class="p">,</span> <span class="n">world_size</span><span class="o">=</span><span class="n">world_size</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">DistributedDataParallel</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_total_params</span><span class="p">(</span><span class="n">module</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
        <span class="n">total_params</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">module</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">total_params</span> <span class="o">+=</span> <span class="n">param</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">total_params</span>

    <span class="n">print_with_rank</span><span class="p">(</span><span class="s1">&#39;Total parameters in model: </span><span class="si">{:,}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">get_total_params</span><span class="p">(</span><span class="n">model</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="section" id="run-the-model">
<h2>Run the model<a class="headerlink" href="#run-the-model" title="Permalink to this headline">Â¶</a></h2>
<p><a class="reference external" href="https://pytorch.org/docs/master/nn.html?highlight=crossentropyloss#torch.nn.CrossEntropyLoss">CrossEntropyLoss</a>
is applied to track the loss and
<a class="reference external" href="https://pytorch.org/docs/master/optim.html?highlight=sgd#torch.optim.SGD">SGD</a>
implements stochastic gradient descent method as the optimizer. The initial
learning rate is set to 5.0. <a class="reference external" href="https://pytorch.org/docs/master/optim.html?highlight=steplr#torch.optim.lr_scheduler.StepLR">StepLR</a> is
applied to adjust the learn rate through epochs. During the
training, we use
<a class="reference external" href="https://pytorch.org/docs/master/nn.html?highlight=nn%20utils%20clip_grad_norm#torch.nn.utils.clip_grad_norm_">nn.utils.clip_grad_norm_</a>
function to scale all the gradient together to prevent exploding.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># In &#39;run_worker&#39;</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
    <span class="n">lr</span> <span class="o">=</span> <span class="mf">5.0</span> <span class="c1"># learning rate</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.95</span><span class="p">)</span>

    <span class="kn">import</span> <span class="nn">time</span>
    <span class="k">def</span> <span class="nf">train</span><span class="p">():</span>
        <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span> <span class="c1"># Turn on the train mode</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">ntokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">stoi</span><span class="p">)</span>

        <span class="c1"># Train only for 50 batches to keep script execution time low.</span>
        <span class="n">nbatches</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">50</span> <span class="o">*</span> <span class="n">bptt</span><span class="p">,</span> <span class="n">train_data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">batch</span><span class="p">,</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">nbatches</span><span class="p">,</span> <span class="n">bptt</span><span class="p">)):</span>
            <span class="n">data</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">train_data</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="c1"># Since the Pipe is only within a single host and process the ``RRef``</span>
            <span class="c1"># returned by forward method is local to this node and can simply</span>
            <span class="c1"># retrieved via ``RRef.local_value()``.</span>
            <span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">local_value</span><span class="p">()</span>
            <span class="c1"># Need to move targets to the device where the output of the</span>
            <span class="c1"># pipeline resides.</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">ntokens</span><span class="p">),</span> <span class="n">targets</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">clip_grad_norm_</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="mf">0.5</span><span class="p">)</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">total_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">log_interval</span> <span class="o">=</span> <span class="mi">10</span>
            <span class="k">if</span> <span class="n">batch</span> <span class="o">%</span> <span class="n">log_interval</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">batch</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">cur_loss</span> <span class="o">=</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="n">log_interval</span>
                <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
                <span class="n">print_with_rank</span><span class="p">(</span><span class="s1">&#39;| epoch </span><span class="si">{:3d}</span><span class="s1"> | </span><span class="si">{:5d}</span><span class="s1">/</span><span class="si">{:5d}</span><span class="s1"> batches | &#39;</span>
                      <span class="s1">&#39;lr </span><span class="si">{:02.2f}</span><span class="s1"> | ms/batch </span><span class="si">{:5.2f}</span><span class="s1"> | &#39;</span>
                      <span class="s1">&#39;loss </span><span class="si">{:5.2f}</span><span class="s1"> | ppl </span><span class="si">{:8.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                        <span class="n">epoch</span><span class="p">,</span> <span class="n">batch</span><span class="p">,</span> <span class="n">nbatches</span> <span class="o">//</span> <span class="n">bptt</span><span class="p">,</span> <span class="n">scheduler</span><span class="o">.</span><span class="n">get_lr</span><span class="p">()[</span><span class="mi">0</span><span class="p">],</span>
                        <span class="n">elapsed</span> <span class="o">*</span> <span class="mi">1000</span> <span class="o">/</span> <span class="n">log_interval</span><span class="p">,</span>
                        <span class="n">cur_loss</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">cur_loss</span><span class="p">)))</span>
                <span class="n">total_loss</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">eval_model</span><span class="p">,</span> <span class="n">data_source</span><span class="p">):</span>
        <span class="n">eval_model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span> <span class="c1"># Turn on the evaluation mode</span>
        <span class="n">total_loss</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="n">ntokens</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="o">.</span><span class="n">stoi</span><span class="p">)</span>
        <span class="c1"># Evaluate only for 50 batches to keep script execution time low.</span>
        <span class="n">nbatches</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">50</span> <span class="o">*</span> <span class="n">bptt</span><span class="p">,</span> <span class="n">data_source</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">nbatches</span><span class="p">,</span> <span class="n">bptt</span><span class="p">):</span>
                <span class="n">data</span><span class="p">,</span> <span class="n">targets</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">data_source</span><span class="p">,</span> <span class="n">i</span><span class="p">)</span>
                <span class="n">output</span> <span class="o">=</span> <span class="n">eval_model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">local_value</span><span class="p">()</span>
                <span class="n">output_flat</span> <span class="o">=</span> <span class="n">output</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">ntokens</span><span class="p">)</span>
                <span class="c1"># Need to move targets to the device where the output of the</span>
                <span class="c1"># pipeline resides.</span>
                <span class="n">total_loss</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">*</span> <span class="n">criterion</span><span class="p">(</span><span class="n">output_flat</span><span class="p">,</span> <span class="n">targets</span><span class="o">.</span><span class="n">cuda</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">rank</span> <span class="o">+</span> <span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">total_loss</span> <span class="o">/</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data_source</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
<p>Loop over epochs. Save the model if the validation loss is the best
weâ€™ve seen so far. Adjust the learning rate after each epoch.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># In &#39;run_worker&#39;</span>
    <span class="n">best_val_loss</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="s2">&quot;inf&quot;</span><span class="p">)</span>
    <span class="n">epochs</span> <span class="o">=</span> <span class="mi">3</span> <span class="c1"># The number of epochs</span>
    <span class="n">best_model</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">epochs</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
        <span class="n">epoch_start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">train</span><span class="p">()</span>
        <span class="n">val_loss</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">val_data</span><span class="p">)</span>
        <span class="n">print_with_rank</span><span class="p">(</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">89</span><span class="p">)</span>
        <span class="n">print_with_rank</span><span class="p">(</span><span class="s1">&#39;| end of epoch </span><span class="si">{:3d}</span><span class="s1"> | time: </span><span class="si">{:5.2f}</span><span class="s1">s | valid loss </span><span class="si">{:5.2f}</span><span class="s1"> | &#39;</span>
              <span class="s1">&#39;valid ppl </span><span class="si">{:8.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="p">(</span><span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">epoch_start_time</span><span class="p">),</span>
                                         <span class="n">val_loss</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">val_loss</span><span class="p">)))</span>
        <span class="n">print_with_rank</span><span class="p">(</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">89</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">val_loss</span> <span class="o">&lt;</span> <span class="n">best_val_loss</span><span class="p">:</span>
            <span class="n">best_val_loss</span> <span class="o">=</span> <span class="n">val_loss</span>
            <span class="n">best_model</span> <span class="o">=</span> <span class="n">model</span>

        <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="evaluate-the-model-with-the-test-dataset">
<h2>Evaluate the model with the test dataset<a class="headerlink" href="#evaluate-the-model-with-the-test-dataset" title="Permalink to this headline">Â¶</a></h2>
<p>Apply the best model to check the result with the test dataset.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># In &#39;run_worker&#39;</span>
    <span class="n">test_loss</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">best_model</span><span class="p">,</span> <span class="n">test_data</span><span class="p">)</span>
    <span class="n">print_with_rank</span><span class="p">(</span><span class="s1">&#39;=&#39;</span> <span class="o">*</span> <span class="mi">89</span><span class="p">)</span>
    <span class="n">print_with_rank</span><span class="p">(</span><span class="s1">&#39;| End of training | test loss </span><span class="si">{:5.2f}</span><span class="s1"> | test ppl </span><span class="si">{:8.2f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">test_loss</span><span class="p">,</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">test_loss</span><span class="p">)))</span>
    <span class="n">print_with_rank</span><span class="p">(</span><span class="s1">&#39;=&#39;</span> <span class="o">*</span> <span class="mi">89</span><span class="p">)</span>

<span class="c1"># Main execution</span>
<span class="kn">import</span> <span class="nn">torch.multiprocessing</span> <span class="k">as</span> <span class="nn">mp</span>

<span class="k">if</span> <span class="vm">__name__</span><span class="o">==</span><span class="s2">&quot;__main__&quot;</span><span class="p">:</span>
    <span class="n">world_size</span> <span class="o">=</span> <span class="mi">2</span>
    <span class="n">mp</span><span class="o">.</span><span class="n">spawn</span><span class="p">(</span><span class="n">run_worker</span><span class="p">,</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">world_size</span><span class="p">,</span> <span class="p">),</span> <span class="n">nprocs</span><span class="o">=</span><span class="n">world_size</span><span class="p">,</span> <span class="n">join</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="output">
<h2>Output<a class="headerlink" href="#output" title="Permalink to this headline">Â¶</a></h2>
<div class="highlight-py notranslate"><div class="highlight"><pre><span></span><span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="n">Total</span> <span class="n">parameters</span> <span class="ow">in</span> <span class="n">model</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span><span class="mi">041</span><span class="p">,</span><span class="mi">453</span><span class="p">,</span><span class="mi">167</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="n">Total</span> <span class="n">parameters</span> <span class="ow">in</span> <span class="n">model</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span><span class="mi">041</span><span class="p">,</span><span class="mi">453</span><span class="p">,</span><span class="mi">167</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">1</span> <span class="o">|</span>    <span class="mi">10</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">5.00</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1414.18</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">48.70</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">1406154472673147092992.00</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">1</span> <span class="o">|</span>    <span class="mi">10</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">5.00</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1414.42</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">48.49</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">1146707511057334927360.00</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">1</span> <span class="o">|</span>    <span class="mi">20</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">5.00</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1260.76</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">42.74</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">3648812398518492672.00</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">1</span> <span class="o">|</span>    <span class="mi">20</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">5.00</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1260.76</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">41.51</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">1064844757565813248.00</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">1</span> <span class="o">|</span>    <span class="mi">30</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">5.00</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1246.80</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">41.85</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">1497706388552644096.00</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">1</span> <span class="o">|</span>    <span class="mi">30</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">5.00</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1246.80</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">40.46</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">373830103285747072.00</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">1</span> <span class="o">|</span>    <span class="mi">40</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">5.00</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1246.69</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">39.76</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">185159839078666368.00</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">1</span> <span class="o">|</span>    <span class="mi">40</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">5.00</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1246.69</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">39.89</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">211756997625874912.00</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">-----------------------------------------------------------------------------------------</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">|</span> <span class="n">end</span> <span class="n">of</span> <span class="n">epoch</span>   <span class="mi">1</span> <span class="o">|</span> <span class="n">time</span><span class="p">:</span> <span class="mf">69.37</span><span class="n">s</span> <span class="o">|</span> <span class="n">valid</span> <span class="n">loss</span>  <span class="mf">2.92</span> <span class="o">|</span> <span class="n">valid</span> <span class="n">ppl</span>    <span class="mf">18.46</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">-----------------------------------------------------------------------------------------</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">-----------------------------------------------------------------------------------------</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">|</span> <span class="n">end</span> <span class="n">of</span> <span class="n">epoch</span>   <span class="mi">1</span> <span class="o">|</span> <span class="n">time</span><span class="p">:</span> <span class="mf">69.39</span><span class="n">s</span> <span class="o">|</span> <span class="n">valid</span> <span class="n">loss</span>  <span class="mf">2.92</span> <span class="o">|</span> <span class="n">valid</span> <span class="n">ppl</span>    <span class="mf">18.46</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">-----------------------------------------------------------------------------------------</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">2</span> <span class="o">|</span>    <span class="mi">10</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">4.51</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1373.91</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">39.77</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">187532281612905856.00</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">2</span> <span class="o">|</span>    <span class="mi">10</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">4.51</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1375.62</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">39.05</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">91344349371016336.00</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">2</span> <span class="o">|</span>    <span class="mi">20</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">4.51</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1250.33</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">30.62</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">19917977906884.78</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">2</span> <span class="o">|</span>    <span class="mi">20</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">4.51</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1250.33</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">30.48</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">17250186491252.32</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">2</span> <span class="o">|</span>    <span class="mi">30</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">4.51</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1250.73</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">29.14</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">4534527326854.47</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">2</span> <span class="o">|</span>    <span class="mi">30</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">4.51</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1250.73</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">29.43</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">6035762659681.65</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">2</span> <span class="o">|</span>    <span class="mi">40</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">4.51</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1249.54</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">23.11</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">10869828323.89</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">2</span> <span class="o">|</span>    <span class="mi">40</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">4.51</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1249.55</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">22.90</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">8785318464.24</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">-----------------------------------------------------------------------------------------</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">|</span> <span class="n">end</span> <span class="n">of</span> <span class="n">epoch</span>   <span class="mi">2</span> <span class="o">|</span> <span class="n">time</span><span class="p">:</span> <span class="mf">69.02</span><span class="n">s</span> <span class="o">|</span> <span class="n">valid</span> <span class="n">loss</span>  <span class="mf">0.94</span> <span class="o">|</span> <span class="n">valid</span> <span class="n">ppl</span>     <span class="mf">2.55</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">-----------------------------------------------------------------------------------------</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">-----------------------------------------------------------------------------------------</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">|</span> <span class="n">end</span> <span class="n">of</span> <span class="n">epoch</span>   <span class="mi">2</span> <span class="o">|</span> <span class="n">time</span><span class="p">:</span> <span class="mf">69.05</span><span class="n">s</span> <span class="o">|</span> <span class="n">valid</span> <span class="n">loss</span>  <span class="mf">0.94</span> <span class="o">|</span> <span class="n">valid</span> <span class="n">ppl</span>     <span class="mf">2.55</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">-----------------------------------------------------------------------------------------</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">3</span> <span class="o">|</span>    <span class="mi">10</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">4.29</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1380.66</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">12.98</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">434052.59</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">3</span> <span class="o">|</span>    <span class="mi">10</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">4.29</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1376.47</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">12.92</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">410203.33</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">3</span> <span class="o">|</span>    <span class="mi">20</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">4.29</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1250.88</span> <span class="o">|</span> <span class="n">loss</span>  <span class="mf">9.80</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">18034.58</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">3</span> <span class="o">|</span>    <span class="mi">20</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">4.29</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1250.88</span> <span class="o">|</span> <span class="n">loss</span>  <span class="mf">9.78</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">17741.88</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">3</span> <span class="o">|</span>    <span class="mi">30</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">4.29</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1251.89</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">10.37</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">32016.45</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">3</span> <span class="o">|</span>    <span class="mi">30</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">4.29</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1251.90</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">10.46</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">34735.08</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">3</span> <span class="o">|</span>    <span class="mi">40</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">4.29</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1250.70</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">10.09</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">24147.61</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">|</span> <span class="n">epoch</span>   <span class="mi">3</span> <span class="o">|</span>    <span class="mi">40</span><span class="o">/</span>   <span class="mi">50</span> <span class="n">batches</span> <span class="o">|</span> <span class="n">lr</span> <span class="mf">4.29</span> <span class="o">|</span> <span class="n">ms</span><span class="o">/</span><span class="n">batch</span> <span class="mf">1250.71</span> <span class="o">|</span> <span class="n">loss</span> <span class="mf">10.08</span> <span class="o">|</span> <span class="n">ppl</span> <span class="mf">23748.31</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">-----------------------------------------------------------------------------------------</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">|</span> <span class="n">end</span> <span class="n">of</span> <span class="n">epoch</span>   <span class="mi">3</span> <span class="o">|</span> <span class="n">time</span><span class="p">:</span> <span class="mf">69.12</span><span class="n">s</span> <span class="o">|</span> <span class="n">valid</span> <span class="n">loss</span>  <span class="mf">0.69</span> <span class="o">|</span> <span class="n">valid</span> <span class="n">ppl</span>     <span class="mf">2.00</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">-----------------------------------------------------------------------------------------</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">-----------------------------------------------------------------------------------------</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">|</span> <span class="n">end</span> <span class="n">of</span> <span class="n">epoch</span>   <span class="mi">3</span> <span class="o">|</span> <span class="n">time</span><span class="p">:</span> <span class="mf">69.12</span><span class="n">s</span> <span class="o">|</span> <span class="n">valid</span> <span class="n">loss</span>  <span class="mf">0.69</span> <span class="o">|</span> <span class="n">valid</span> <span class="n">ppl</span>     <span class="mf">2.00</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">-----------------------------------------------------------------------------------------</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">=========================================================================================</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">|</span> <span class="n">End</span> <span class="n">of</span> <span class="n">training</span> <span class="o">|</span> <span class="n">test</span> <span class="n">loss</span>  <span class="mf">0.60</span> <span class="o">|</span> <span class="n">test</span> <span class="n">ppl</span>     <span class="mf">1.83</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">0</span><span class="p">]:</span> <span class="o">=========================================================================================</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">=========================================================================================</span>
<span class="p">[</span><span class="n">RANK</span> <span class="mi">1</span><span class="p">]:</span> <span class="o">|</span> <span class="n">End</span> <span class="n">of</span> <span class="n">training</span> <span class="o">|</span> <span class="n">test</span> <span class="n">loss</span>  <span class="mf">0.60</span> <span class="o">|</span> <span class="n">test</span> <span class="n">ppl</span>     <span class="mf">1.83</span>
</pre></div>
</div>
<p class="sphx-glr-timing"><strong>Total running time of the script:</strong> ( 0 minutes  0.000 seconds)</p>
<div class="sphx-glr-footer class sphx-glr-footer-example docutils container" id="sphx-glr-download-advanced-ddp-pipeline-py">
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/02d52208d4f450a5969d337c9a2a7daf/ddp_pipeline.py"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Python</span> <span class="pre">source</span> <span class="pre">code:</span> <span class="pre">ddp_pipeline.py</span></code></a></div>
<div class="sphx-glr-download docutils container">
<a class="reference download internal" download="" href="../_downloads/b533324ee4e399db7dcab3c7ecd566de/ddp_pipeline.ipynb"><code class="xref download docutils literal notranslate"><span class="pre">Download</span> <span class="pre">Jupyter</span> <span class="pre">notebook:</span> <span class="pre">ddp_pipeline.ipynb</span></code></a></div>
</div>
<p class="sphx-glr-signature"><a class="reference external" href="https://sphinx-gallery.readthedocs.io">Gallery generated by Sphinx-Gallery</a></p>
</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../beginner/deeplabv3_on_ios.html" class="btn btn-neutral float-right" title="Image Segmentation DeepLabV3 on iOS" accesskey="n" rel="next">Next <img src="../_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="../intermediate/pipeline_tutorial.html" class="btn btn-neutral" title="Training Transformer models using Pipeline Parallelism" accesskey="p" rel="prev"><img src="../_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr class="rating-hr hr-top">
      <div class="rating-container">
        <div class="rating-prompt">Rate this Tutorial</div>
        <div class="stars-outer">
          <i class="far fa-star" title="1 Star" data-behavior="tutorial-rating" data-count="1"></i>
          <i class="far fa-star" title="2 Stars" data-behavior="tutorial-rating" data-count="2"></i>
          <i class="far fa-star" title="3 Stars" data-behavior="tutorial-rating" data-count="3"></i>
          <i class="far fa-star" title="4 Stars" data-behavior="tutorial-rating" data-count="4"></i>
          <i class="far fa-star" title="5 Stars" data-behavior="tutorial-rating" data-count="5"></i>
        </div>
      </div>
    <hr class="rating-hr hr-bottom"/>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017, PyTorch.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">Training Transformer models using Distributed Data Parallel and Pipeline Parallelism</a><ul>
<li><a class="reference internal" href="#define-the-model">Define the model</a></li>
<li><a class="reference internal" href="#start-multiple-processes-for-training">Start multiple processes for training</a></li>
<li><a class="reference internal" href="#load-and-batch-data">Load and batch data</a><ul>
<li><a class="reference internal" href="#functions-to-generate-input-and-target-sequence">Functions to generate input and target sequence</a></li>
</ul>
</li>
<li><a class="reference internal" href="#model-scale-and-pipe-initialization">Model scale and Pipe initialization</a></li>
<li><a class="reference internal" href="#run-the-model">Run the model</a></li>
<li><a class="reference internal" href="#evaluate-the-model-with-the-test-dataset">Evaluate the model with the test dataset</a></li>
<li><a class="reference internal" href="#output">Output</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
         <script type="text/javascript" src="../_static/jquery.js"></script>
         <script type="text/javascript" src="../_static/underscore.js"></script>
         <script type="text/javascript" src="../_static/doctools.js"></script>
         <script type="text/javascript" src="../_static/clipboard.min.js"></script>
         <script type="text/javascript" src="../_static/copybutton.js"></script>
         <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
     

  

  <script type="text/javascript" src="../_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="../_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>

<script>

  window.dataLayer = window.dataLayer || [];

  function gtag(){dataLayer.push(arguments);}

  gtag('js', new Date());
  gtag('config', 'UA-117752657-2');

</script>

<script>
  !function(f,b,e,v,n,t,s)
  {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
  n.callMethod.apply(n,arguments):n.queue.push(arguments)};
  if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
  n.queue=[];t=b.createElement(e);t.async=!0;
  t.src=v;s=b.getElementsByTagName(e)[0];
  s.parentNode.insertBefore(t,s)}(window,document,'script',
  'https://connect.facebook.net/en_US/fbevents.js');
  fbq('init', '243028289693773');
  fbq('track', 'PageView');

  $("[data-behavior='call-to-action-event']").on('click', function(){
    fbq('trackCustom', "Download", {
      tutorialTitle: $('h1:first').text(),
      downloadLink: this.href,
      tutorialLink: window.location.href,
      downloadTitle: $(this).attr("data-response")
    });
    ga('send', {
      hitType: 'event',
      eventCategory: $(this).attr("data-response"),
      eventAction: 'click',
      eventLabel: window.location.href
    });

    gtag('event', 'click', {
      'event_category': $(this).attr("data-response"),
      'event_label': $("h1").first().text(),
      'tutorial_link': window.location.href
    });
   });

   $("[data-behavior='tutorial-rating']").on('click', function(){
    fbq('trackCustom', "Tutorial Rating", {
      tutorialLink: window.location.href,
      tutorialTitle: $('h1:first').text(),
      rating: $(this).attr("data-count")
    });

    gtag('event', 'click', {
      'event_category': 'Tutorial Rating',
      'event_label': $("h1").first().text(),
      'value': $(this).attr("data-count")
    });
   });

   if (location.pathname == "/") {
     $(".rating-container").hide();
     $(".hr-bottom").hide();
   }
</script>

<noscript>
  <img height="1" width="1"
  src="https://www.facebook.com/tr?id=243028289693773&ev=PageView
  &noscript=1"/>
</noscript>

<script type="text/javascript">
  var collapsedSections = ['PyTorch Recipes', 'Image and Video', 'Audio', 'Text', 'Reinforcement Learning', 'Deploying PyTorch Models in Production', 'Code Transforms with FX', 'Frontend APIs', 'Extending PyTorch', 'Model Optimization', 'Parallel and Distributed Training', 'Mobile'];
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
            <a href="https://www.youtube.com/pytorch" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebookâ€™s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="../_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li class="active">
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/vision/stable/index.html">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/elastic/">TorchElastic</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="../_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>